{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW6_lesson_7_task_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KirPim/DS_school_2020_home_work/blob/main/HW6_lesson_7_task_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDkG3Bis38V_"
      },
      "source": [
        "# Домашнее задание к 7 уроку.\n",
        "\n",
        "**Дедлайн: 23.12.2020**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_frQ-789isH"
      },
      "source": [
        "colab: https://colab.research.google.com/drive/1KLD5pDCa0ka_g1U4D2ExihaaEwXzfTPW?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzhnPFbL3igE"
      },
      "source": [
        "**ФОРМАТ ОТЧЕТНОСТИ:** pdf-файл с решенными задачами (задачи 2-9), ноутбук с проверкой решения этих задач (при помощи numpy), и pdf файл с отчетом по 1-ой задаче (краткий пересказ статьи). Вы можете оформить решения с использованием Markdown (писать текст прямо в юпитер ноутбуке), Latex, Word или же решить в тетради и сформировать pdf из фото.\n",
        "\n",
        "Итого: 2 pdf файла.\n",
        "\n",
        "Все задания необходимо выполнять ВРУЧНУЮ. А также проверить корректность полученных результатов с использованием Numpy.\n",
        "\n",
        "Туториал как писать \"Latex-формулы\" прямо в Юпитере:\n",
        "https://www.youtube.com/watch?v=vSc25kdgecg\n",
        "\n",
        "Ноутбук с примером формул: https://nbviewer.jupyter.org/github/postlogist/course_opt/blob/master/jupyter_tutorial/02_markdown.ipynb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU2u4fG55fBq"
      },
      "source": [
        "## Пример\n",
        "\n",
        "\n",
        "Найдем ранг матрицы \n",
        "\n",
        "$$\\begin{pmatrix}\n",
        "1 & 2 & 3 & 4 & 5\\\\ \n",
        "2 & 5 & 8 & 11 & 14\\\\ \n",
        "3 & 9 & 14 & 20 & 26\\\\ \n",
        "5 & 14 & 22 & 31 & 40\n",
        "\\end{pmatrix}.$$\n",
        "\n",
        "Четвертая строка является суммой второй и третьей строк, а значит, ее можно отбросить:\n",
        "\n",
        "$$\\begin{pmatrix}\n",
        "1 & 2 & 3 & 4 & 5\\\\ \n",
        "2 & 5 & 8 & 11 & 14\\\\ \n",
        "3 & 9 & 14 & 20 & 26\n",
        "\\end{pmatrix}.$$\n",
        "\n",
        "Из второй и третьей строк вычтем первую, умноженную на $2$ и $3$ соответственно:\n",
        "\n",
        "$$\\begin{pmatrix}\n",
        "1 & 2 & 3 & 4 & 5\\\\ \n",
        "0 & 1 & 2 & 3 & 4\\\\ \n",
        "0 & 2 & 5 & 8 & 11\n",
        "\\end{pmatrix}.$$\n",
        "\n",
        "И вычтем из третьей строки вторую, умноженную на $2$:\n",
        "\n",
        "$$\\begin{pmatrix}\n",
        "1 & 2 & 3 & 4 & 5\\\\ \n",
        "0 & 1 & 2 & 3 & 4\\\\ \n",
        "0 & 0 & 1 & 2 & 3\n",
        "\\end{pmatrix}.$$\n",
        "\n",
        "Таким образом, ранг матрицы равен $3$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3mJUpE65vak",
        "outputId": "3f721417-8cc7-480e-b988-5106748cd4b0"
      },
      "source": [
        "# Проверка\n",
        "\n",
        "import numpy as np\n",
        "a = [1, 2, 3, 4, 5]\n",
        "b = [2, 5, 8, 11, 14]\n",
        "c = [3, 9, 14, 20, 26]\n",
        "d = [5, 14, 22, 31, 40]\n",
        "\n",
        "x = np.array([a, b, c, d])\n",
        "r = np.linalg.matrix_rank(x)\n",
        "\n",
        "print(f'Ранг матрицы: {r}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ранг матрицы: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NlQHLnE5iV-"
      },
      "source": [
        "# Задачи"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOoLPT-d232H"
      },
      "source": [
        "**1.** Прочитать статью http://www.scielo.org.mx/pdf/cys/v18n3/v18n3a7.pdf и сделать следующее:\n",
        "\n",
        "- Написать кратко (не более 300 слов (минимум 100), отчет в формате pdf) о различиях между cosine similarity и soft similarity. Привести примеры использования и написать собственный пример вычисления cosine similarity и soft similarity для произвольных векторов (не брать вектора из статьи! надо самим придумать координаты/размерность векторов)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A79cNRu3BUA"
      },
      "source": [
        "__2.__ Найти сумму и произведение матриц $A=\\begin{pmatrix}\n",
        "1 & -2\\\\ \n",
        "3 & 0\n",
        "\\end{pmatrix}$ и $B=\\begin{pmatrix}\n",
        "4 & -1\\\\ \n",
        "0 & 5\n",
        "\\end{pmatrix}.$\n",
        "\n",
        "__3.__ Из закономерностей сложения и умножения матриц на число можно сделать вывод, что матрицы одного размера образуют линейное пространство. Вычислить линейную комбинацию $3A-2B+4C$ для матриц $A=\\begin{pmatrix}\n",
        "1 & 7\\\\ \n",
        "3 & -6\n",
        "\\end{pmatrix}$, $B=\\begin{pmatrix}\n",
        "0 & 5\\\\ \n",
        "2 & -1\n",
        "\\end{pmatrix}$, $C=\\begin{pmatrix}\n",
        "2 & -4\\\\ \n",
        "1 & 1\n",
        "\\end{pmatrix}.$\n",
        "    \n",
        "__4.__ Дана матрица $A=\\begin{pmatrix}\n",
        "4 & 1\\\\ \n",
        "5 & -2\\\\ \n",
        "2 & 3\n",
        "\\end{pmatrix}$.\n",
        "Вычислить $AA^{T}$ и $A^{T}A$.\n",
        "\n",
        "__5*.__ Написать на Python функцию для перемножения двух произвольных матриц, не используя NumPy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-naSOZaf3L7s"
      },
      "source": [
        "\n",
        "__6.__ Вычислить определитель (используйте любой удобный для вас способ вычисления определителя: через миноры, через перестановки или другой):\n",
        "\n",
        "   a)\n",
        "\n",
        "$$\\begin{vmatrix}\n",
        "sinx & -cosx\\\\ \n",
        "cosx & sinx\n",
        "\\end{vmatrix};$$\n",
        "\n",
        "   б)\n",
        "    \n",
        "$$\\begin{vmatrix}\n",
        "8 & 4 & 6\\\\ \n",
        "0 & 5 & 1\\\\ \n",
        "0 & 0 & 9\n",
        "\\end{vmatrix};$$\n",
        "    \n",
        "   в)\n",
        "\n",
        "$$\\begin{vmatrix}\n",
        "2 & 3 & 4\\\\ \n",
        "5 & 6 & 7\\\\ \n",
        "8 & 9 & 10\n",
        "\\end{vmatrix}.$$\n",
        "\n",
        "\n",
        "__7.__ Определитель матрицы $A$ равен $4$. Найти:\n",
        "\n",
        "   а) $det(A^{2})$;\n",
        "    \n",
        "   б) $det(A^{T})$;\n",
        "    \n",
        "   в) $det(2A)$.\n",
        "   \n",
        "__8.__  Доказать, что матрица\n",
        "\n",
        "$$\\begin{pmatrix}\n",
        "-2 & 7 & -3\\\\ \n",
        "4 & -14 & 6\\\\ \n",
        "-3 & 7 & 13\n",
        "\\end{pmatrix}$$\n",
        "   \n",
        "вырожденная.\n",
        "\n",
        "__9.__ Найти ранг матрицы:\n",
        "\n",
        "   а) $\\begin{pmatrix}\n",
        "1 & 2 & 3\\\\ \n",
        "1 & 1 & 1\\\\ \n",
        "2 & 3 & 4\n",
        "\\end{pmatrix};$\n",
        "\n",
        "   б) $\\begin{pmatrix}\n",
        "0 & 0 & 2 & 1\\\\ \n",
        "0 & 0 & 2 & 2\\\\ \n",
        "0 & 0 & 4 & 3\\\\ \n",
        "2 & 3 & 5 & 6\n",
        "\\end{pmatrix}.$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekAaqmaE3E1T"
      },
      "source": [
        "# Доп материалы\n",
        "1. [Способы задать матрицу в NumPy](https://docs.scipy.org/doc/numpy-1.10.1/user/basics.creation.html).\n",
        "2. [numpy.transpose](https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.transpose.html).\n",
        "3. [array.T](https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.ndarray.T.html).\n",
        "4. [Перемножение матриц в NumPy](https://docs.scipy.org/doc/numpy-1.10.0/reference/routines.linalg.html#matrix-and-vector-products).\n",
        "\n",
        "5. [Определитель матрицы в NumPy](https://docs.scipy.org/doc/numpy-1.14.2/reference/generated/numpy.linalg.det.html)\n",
        "\n",
        "6. [Ранг матрицы в NumPy](https://docs.scipy.org/doc/numpy-1.14.2/reference/generated/numpy.linalg.matrix_rank.html)\n",
        "\n",
        "7. [Обращение матриц в NumPy](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.inv.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jidQNbg_Lzz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3pTM4h38FII"
      },
      "source": [
        "#Решение\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3g4O7YGza08"
      },
      "source": [
        "__1)__\r\n",
        "Статья раскрывает сущность таких понятий, как cosin similarity и soft cosin measure. Если говорить общими словами, то данные методы позволяют находить степень сходства между текстовыми конструкциями, спроецированными в векторное пространство. \r\n",
        "Различие между этими понятиями: cosin similarity определяет косинус угла между двумя векторами, содержащми в качестве компонент частоты вхождений каждого слова в первом и втором тексте, соответственно; soft cosin measure учитывает также неявное сходство между словами-базисами (мера $s_{ij}$), как, например, в случае с синонимами, которые пишутся по-разному, но имеют один смысл. \r\n",
        "В статье также рассматриваются различные модели построения меры сходства $sim$ как функций от расстояния Левенштейна.\r\n",
        "Помимо этого, приведен эксперимент Entranse Exam Task, на котором тестировалась и сравнивалась эффективность cosin similarity и soft cosin similarity. Эксперимент заключался в том, что к определенному набору текстов задаются вопросы с вариантами ответов, и машина на основе сходства содержания вопросов, ответов и самого текста, должна выбирать правильные ответы, отражающие суть исходых текстов. В результате soft cosin similarity показал более высокие результаты. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_5fstQO1pM7"
      },
      "source": [
        "s = '''\r\n",
        "Статья раскрывает сущность таких понятий, как cosin similarity и soft cosin measure. Если говорить общими словами, то данные методы позволяют находить степень сходства между текстовыми конструкциями, спроецированными в векторное пространство. \r\n",
        "Различие между этими понятиями: cosin similarity определяет косинус угла между двумя векторами, содержащми в качестве компонент частоты вхождений каждого слова в первом и втором тексте, соответственно; soft cosin measure учитывает также неявное сходство между словами-базисами (мера $s_{ij}$), как, например, в случае с синонимами, которые пишутся по-разному, но имеют один смысл. \r\n",
        "В статье также рассматриваются различные модели построения меры сходства $sim$ как функций от расстояния Левенштейна.\r\n",
        "Помимо этого, приведен эксперимент Entranse Exam Task, на котором тестировалась и сравнивалась эффективность cosin similarity и soft cosin similarity. Эксперимент заключался в том, что к определенному набору текстов задаются вопросы с вариантами ответов, и машина на основе сходства содержания вопросов, ответов и самого текста, должна выбирать правильные ответы, отражающие суть исходых текстов. В результате soft cosin similarity показал более высокие результаты. \r\n",
        "'''"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUkmUD0B1weK",
        "outputId": "18417a1a-f87d-4ccd-88a0-60bb46d219cf"
      },
      "source": [
        "n = len(s.split(' '))\r\n",
        "print(f'Количество слов: {n}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество слов: 156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeibKagE8eED"
      },
      "source": [
        "Пример.\r\n",
        "\r\n",
        "$a:$ удача награда за смелость\r\n",
        "\r\n",
        "$b:$ храброму воину повезло\r\n",
        "\r\n",
        "Слова: удача, награда, смелость, храбрый, воин, повезло\r\n",
        "\r\n",
        "$a = (1, 1, 1, 0, 0, 0)$\r\n",
        "\r\n",
        "$b = (0, 0, 0, 1, 1, 1)$\r\n",
        "\r\n",
        "$cosin$ будет равен 0, поскольку скалярное произведение $a\\cdot b$ будет нулевым, т.е. сходство между фразами в таком виде нет.\r\n",
        "\r\n",
        "При этом можем говорить о неявном сходстве $(s_{ij}=1)$ таких слов, как \"удача - повезло\", \"смелость - храбрый\".\r\n",
        "\r\n",
        "В этом случае будем иметь матрицы 6x6:\r\n",
        "$$\r\n",
        "A=\\begin{pmatrix}\r\n",
        "a_{11} & a_{12} & a_{13} & a_{14} & a_{15} & a_{16}\\\\ \r\n",
        "a_{21} & a_{22} & a_{23} & a_{24} & a_{25} & a_{26}\\\\ \r\n",
        "a_{31} & a_{32} & a_{33} & a_{34} & a_{35} & a_{36}\\\\\r\n",
        "a_{41} & a_{42} & a_{43} & a_{44} & a_{45} & a_{46}\\\\\r\n",
        "a_{51} & a_{52} & a_{53} & a_{54} & a_{55} & a_{56}\\\\\r\n",
        "a_{61} & a_{62} & a_{63} & a_{64} & a_{65} & a_{66}\r\n",
        "\\end{pmatrix}\r\n",
        "=\\begin{pmatrix}\r\n",
        "1 & 0 & 0 & 0 & 0 & 0,5\\\\ \r\n",
        "0 & 1 & 0 & 0 & 0 & 0\\\\ \r\n",
        "0 & 0 & 1 & 0,5 & 0 & 0\\\\\r\n",
        "0 & 0 & 0,5 & 0 & 0 & 0\\\\\r\n",
        "0 & 0 & 0 & 0 & 0 & 0\\\\\r\n",
        "0,5 & 0 & 0 & 0 & 0 & 0\r\n",
        "\\end{pmatrix}\r\n",
        "$$\r\n",
        "\r\n",
        "$$\r\n",
        "B=\\begin{pmatrix}\r\n",
        "b_{11} & b_{12} & b_{13} & b_{14} & b_{15} & b_{16}\\\\ \r\n",
        "b_{21} & b_{22} & b_{23} & b_{24} & b_{25} & b_{26}\\\\ \r\n",
        "b_{31} & b_{32} & b_{33} & b_{34} & b_{35} & b_{36}\\\\\r\n",
        "b_{41} & b_{42} & b_{43} & b_{44} & b_{45} & b_{46}\\\\\r\n",
        "b_{51} & b_{52} & b_{53} & b_{54} & b_{55} & b_{56}\\\\\r\n",
        "b_{61} & b_{62} & b_{63} & b_{64} & b_{65} & b_{66}\r\n",
        "\\end{pmatrix}\r\n",
        "=\\begin{pmatrix}\r\n",
        "0 & 0 & 0 & 0 & 0 & 0,5\\\\ \r\n",
        "0 & 0 & 0 & 0 & 0 & 0\\\\ \r\n",
        "0 & 0 & 0 & 0,5 & 0 & 0\\\\\r\n",
        "0 & 0 & 0,5 & 1 & 0 & 0\\\\\r\n",
        "0 & 0 & 0 & 0 & 1 & 0\\\\\r\n",
        "0,5 & 0 & 0 & 0 & 0 & 1\r\n",
        "\\end{pmatrix}\r\n",
        "$$\r\n",
        "\r\n",
        "$$soft cosine = \\frac{0,5^2\\cdot 4}{0,5^2\\cdot 4 + 3}=\\frac{1}{4}$$\r\n"
      ]
    }
  ]
}